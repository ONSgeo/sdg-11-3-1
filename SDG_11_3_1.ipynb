{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDG indicator 11.3.1: Ratio of land consumption rate to population growth rate\n",
    "\n",
    "- #### import datasets: \n",
    "     - #### mid-year opulation estimates from ONS for latest year (e.g 2019) and previous year (3 years before)\n",
    "     - #### land area datasets from OS for latest year (e.g 2019) and previous year (3 years before)\n",
    "- #### check LAD boundary changes between the 2year periods\n",
    "- #### calculate population growth rate\n",
    "- #### calculate land consumption rate\n",
    "- #### calculate Ratio of land consumption rate to population growth rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, merge\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "# print(Path('.').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File R:\\SDGs\\SDG_11_3_1\\data\\population\\SAPE20DT1_mid2016_lsoa_ew.csv does not exist: 'R:\\\\SDGs\\\\SDG_11_3_1\\\\data\\\\population\\\\SAPE20DT1_mid2016_lsoa_ew.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-09635fcf5f3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# read population data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# make sure all columns with numbers have float dtype by using (df = pd.read_csv(<PATH>, thousands=',')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpop_est16ew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'R:\\SDGs\\SDG_11_3_1\\data\\population\\SAPE20DT1_mid2016_lsoa_ew.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthousands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LSOA11CD'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mpop_est19ew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'R:\\SDGs\\SDG_11_3_1\\data\\population\\SAPE22DT2_mid2019_lsoa_ew.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthousands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LSOA11CD'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mpop_est16sc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'R:\\SDGs\\SDG_11_3_1\\data\\population\\SAPE16_mid2016_dz_sc.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthousands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DZ2011CD'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File R:\\SDGs\\SDG_11_3_1\\data\\population\\SAPE20DT1_mid2016_lsoa_ew.csv does not exist: 'R:\\\\SDGs\\\\SDG_11_3_1\\\\data\\\\population\\\\SAPE20DT1_mid2016_lsoa_ew.csv'"
     ]
    }
   ],
   "source": [
    "#calculate Population Growth rate (PGR) = LN(Pop_t+n/Pop_t )/(y)\n",
    "     # Where: LN is the natural logarithm value\n",
    "         # Pop_t is the total population within the urban area/city in the past/initial year\n",
    "         # Pop_t+n is the total population within the urban area/city in the current/final year\n",
    "         # y is the number of years between the two measurement periods\n",
    "\n",
    "# read population data \n",
    "    # make sure all columns with numbers have float dtype by using (df = pd.read_csv(<PATH>, thousands=',')\n",
    "pop_est16ew = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\data\\population\\SAPE20DT1_mid2016_lsoa_ew.csv',thousands=',').set_index('LSOA11CD')\n",
    "pop_est19ew = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\data\\population\\SAPE22DT2_mid2019_lsoa_ew.csv',thousands=',').set_index('LSOA11CD')\n",
    "pop_est16sc = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\data\\population\\SAPE16_mid2016_dz_sc.csv',thousands=',').set_index('DZ2011CD')\n",
    "pop_est19sc = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\data\\population\\SAPE19_mid2019_dz_sc.csv',thousands=',').set_index('DZ2011CD')\n",
    "\n",
    "    # remove whitespace before and after column names\n",
    "pop_est16ew.columns = pop_est16ew.columns.str.strip()\n",
    "pop_est19ew.columns = pop_est19ew.columns.str.strip()\n",
    "pop_est16sc.columns = pop_est16sc.columns.str.strip()\n",
    "pop_est19sc.columns = pop_est19sc.columns.str.strip()\n",
    "\n",
    "display(pop_est16ew.head())\n",
    "display(pop_est19ew.head())\n",
    "display(pop_est16sc.head())\n",
    "display(pop_est19sc.head())\n",
    "\n",
    "\n",
    "    # merge population tables for england and wales and for scotland for 2016 and 2019\n",
    "pop_est19_16ew = pd.merge(pop_est19ew, pop_est16ew, on='LSOA11CD', how='outer', indicator=True, suffixes=('_19','_16'))\n",
    "pop_est19_16sc = pd.merge(pop_est19sc, pop_est16sc, on='DZ2011CD', how='outer', indicator=True, suffixes=('_19','_16'))\n",
    "\n",
    "    # change data type from string to float for columns with population data\n",
    "#pop_est19_16ew['All_Ages_2016']=pop_est19_16ew['All_Ages_2016'].str.replace(',','').astype(np.float32)\n",
    "#pop_est19_16ew['All_Ages_2019']=pop_est19_16ew['All_Ages_2019'].str.replace(',','').astype(np.float32)\n",
    "#pop_est19_16sc['All_Ages_2016']=pop_est19_16sc['All_Ages_2016'].str.replace(',','').astype(np.float32)\n",
    "#pop_est19_16sc['All_Ages_2019']=pop_est19_16sc['All_Ages_2019'].str.replace(',','').astype(np.float32)\n",
    "\n",
    "    #check if merge operation has run successfully\n",
    "display(pop_est19_16ew.head())\n",
    "display(pop_est19_16sc.head())\n",
    "\n",
    "#calculate Population Growth rate (PGR) = LN(Pop_t+n/Pop_t )/(y)\n",
    "\n",
    "    #create new column (pgr19_16) and calculate PGR\n",
    "pop_est19_16ew['pgr19_16'] = np.log(pop_est19_16ew['All_Ages_2019']/pop_est19_16ew['All_Ages_2016'])/3\n",
    "pop_est19_16sc['pgr19_16'] = np.log(pop_est19_16sc['All_Ages_2019']/pop_est19_16sc['All_Ages_2016'])/3\n",
    "\n",
    "    #check if code has run successfully\n",
    "display(pop_est19_16ew['pgr19_16'].head())\n",
    "display(pop_est19_16sc['pgr19_16'].head())\n",
    "\n",
    "    # write table with pgr calculation to file\n",
    "pop_est19_16ew.to_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\pgr_19_16ew.csv')\n",
    "pop_est19_16sc.to_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\pgr_19_16sc.csv')\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate Land Consumption Rate (LCR) = ((Vpresent - Vpast)/Vpast)/(t)\n",
    "     # where : Vpresent is total built-up area in current year\n",
    "            # Vpast is total built-up area in past year\n",
    "            # (t) is number of years between Vpresnt and Vpast (or length in years of the period considered)\n",
    "\n",
    "# read land_area data \n",
    "    # make sure all columns with numbers should have float dtype by using (df = pd.read_csv(<PATH>, thousands=',')  \n",
    "land_area16gb = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\data\\OS\\lsoa2016_landcover_area_GB.csv', thousands=',')\n",
    "land_area19_sc = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\data\\OS\\lsoa2019_landcover_area_sc.csv', thousands=',')\n",
    "land_area19_ew = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\data\\OS\\lsoa2019_landcover_area_ew.csv', thousands=',')\n",
    "\n",
    "\n",
    "    # clean columns names by removing whitespaces before and afer column names\n",
    "land_area16gb.columns = land_area16gb.columns.str.strip()\n",
    "land_area19_sc.columns = land_area19_sc.columns.str.strip()\n",
    "land_area19_ew.columns = land_area19_ew.columns.str.strip()\n",
    "\n",
    "    #inspect imported data visually\n",
    "display(land_area16gb.head())\n",
    "display(land_area19_sc.head())\n",
    "display(land_area19_ew.head())\n",
    "\n",
    "    #split land_area file for 2016 into England and Wales (EW) and Scotland (SC) (only necessary step because OS data is mixed between OAs for SC and LSOAs for EW)\n",
    "filt_ew=(land_area16gb['CTRY']=='E') | (land_area16gb['CTRY']=='W') # filter to separate EW data\n",
    "filt_sc=(land_area16gb['CTRY']=='S') # # filter to separate SC data\n",
    "\n",
    "land_area16_ew=land_area16gb.loc[filt_ew]\n",
    "land_area16_sc=land_area16gb.loc[filt_sc]\n",
    "\n",
    "    #rename SC column names to SC format \n",
    "land_area16_sc.rename({'LSOA11CD':'DataZone2011Code','LSOA11NM':'DataZone2011Name','LAD16CD':'CouncilArea2016Code','LAD16NM':'CouncilArea2016Name'}, axis=1, inplace=True)\n",
    "    #write 2016 land_area files to file\n",
    "land_area16_ew.to_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area16_ew.csv')\n",
    "land_area16_sc.to_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area16_sc.csv')\n",
    "\n",
    "display(land_area16_ew.head())\n",
    "display(land_area16_sc.head())\n",
    "\n",
    "    #filter landcover type = manmade for 2019 data\n",
    "filt_19ewmm = (land_area19_ew['landcover_type']=='Manmade') # filter 'manmade' landcover for EW\n",
    "land_area19_ewmm = land_area19_ew.loc[filt_19ewmm]\n",
    "land_area19_ewmm.to_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area19_ewmm.csv')\n",
    "\n",
    "filt_19scmm = (land_area19_sc['landcover_type']=='Manmade') # filter 'manmade' landcover for SC\n",
    "land_area19_scmm = land_area19_sc[['CTRY','DataZone2011Code','CouncilArea2011Code','landcover_type','area_2019']].loc[filt_19scmm]\n",
    "   # aggregate Scotland OAs to DZs (equavalent of LSOA in EW)\n",
    "land_area19_scdzmm = land_area19_scmm.groupby(['CouncilArea2011Code','DataZone2011Code','landcover_type']).sum()\n",
    "land_area19_scdzmm.to_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area19_scdzmm.csv') #write to csv\n",
    "\n",
    "display(land_area19_ewmm.head()) # EW LSOA 'manmade' land_area \n",
    "display(land_area19_scdzmm.head()) # EW DZ 'manmade' land_area\n",
    "\n",
    "# calculate Land Consumption Rate (LCR) = ((Vpresent - Vpast)/Vpast)/(t)\n",
    "      \n",
    "    #read land_area files and merge to calculate LCR\n",
    "land_area16_ew = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area16_ew.csv').set_index('LSOA11CD')\n",
    "land_area16_sc = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area16_sc.csv').set_index('DataZone2011Code')\n",
    "land_area19_scdzmm = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area19_scdzmm.csv').set_index('DataZone2011Code')\n",
    "land_area19_ewmm = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area19_ewmm.csv').set_index('LSOA11CD')\n",
    "                             \n",
    "    # merge 2019 and 2016 land_area files for EW and SC to create one table for each \n",
    "land_area19_16ewmm = pd.merge(land_area19_ewmm, land_area16_ew, on='LSOA11CD', how='outer', indicator=True, suffixes=('_19','_16'))\n",
    "land_area19_16scmm = pd.merge(land_area19_scdzmm, land_area16_sc, on='DataZone2011Code', how='outer', indicator=True, suffixes=('_19','_16'))\n",
    "   #check if code has run successfully\n",
    "#display(land_area19_16ewmm.head())\n",
    "#display(land_area19_16scmm.head())\n",
    "                                                                   \n",
    "    #write merge output to file\n",
    "land_area19_16ewmm.to_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area19_16ewmm.csv')\n",
    "land_area19_16scmm.to_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area19_16scmm.csv')\n",
    " \n",
    "    #check and remove unwanted columns\n",
    "#land_area19_16ewmm.columns\n",
    "#land_area19_16scmm.columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #check and remove unwanted columns\n",
    "display(land_area19_16ewmm.columns)\n",
    "display(land_area19_16scmm.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calculate Land Consumption Rate (LCR) = ((Vpresent - Vpast)/Vpast)/(t) \n",
    "lcr19_16ewmm['LCR2016_19'] = (lcr19_16ewmm['area_2019']-lcr19_16ewmm['area_2016'])/3\n",
    "lcr19_16scmm['LCR2016_19'] = (lcr19_16scmm['area_2019']-lcr19_16scmm['area_2016'])/3      \n",
    "                                                                   \n",
    "display(lcr19_16ewmm[LCR2016_19].head())   \n",
    "display(lcr19_16escmm[LCR2016_19].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Ratio of land consumption rate to population growth rate (LCRPGR)\n",
    "\n",
    "            # LCRPGR = (Land Consumption Rate)/(Population Growth Rate)\n",
    "    \n",
    "# read population (PGR) data files and land_area (LCR) data files\n",
    "pop_est19_16ew = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\pgr_19_16ew.csv')\n",
    "pop_est19_16sc = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\pgr_19_16sc.csv')\n",
    "land_area19_16ewmm = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area19_16ewmm.csv')\n",
    "land_area19_16scmm = pd.read_csv(r'R:\\SDGs\\SDG_11_3_1\\intermediate\\land_area19_16scmm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LAD boundaries for 2016 and 2019\n",
    "ladboundaries = [r'R:\\SDGs\\SDG_11_3_1\\data\\lad\\LAD_DEC_2019_UK_BFE.shp',r'R:\\SDGs\\SDG_11_3_1\\data\\lad\\Local_Authority_Districts__December_2016__GB_BFE.shp']\n",
    "for lad in ladboundaries:\n",
    "    lad_gdf = gpd.read_file(lad)\n",
    "    display(lad_gdf.head()) # check if code has run\n",
    "    \n",
    "    \n",
    "    #plot lad bundaries\n",
    "    ladsplot = lad_gdf.plot(\n",
    "    color='none', edgecolor='red')\n",
    "    plt.plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
